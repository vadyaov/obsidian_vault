---
sticker: emoji//2601-fe0f
---
### **Введение в Impala**
**Impala** – это массово-параллельный механизм интерактивного выполнения SQL-запросов к данным, хранящимся в Apache Hadoop (HDFS и HBase), написанный на языке С++ и распространяющийся по лицензии Apache 2.0. Также Impala называют MPP-движком (Massively Parallel Processing), распределенной СУБД и даже базой данных стека SQL-on-Hadoop.

Impala обеспечивает быстрые и интерактивные SQL-запросы непосредственно к данным Apache Hadoop, хранящимся в HDFS, HBase или Amazon Simple Storage Service (S3).
Помимо использования той же единой платформы хранения, Impala также использует те же метаданные, синтаксис SQL (Hive SQL), ODBC-драйвер и пользовательский интерфейс (интерфейс запросов Impala в Hue), что и Apache Hive.Это создает знакомую и единую платформу для выполнения запросов в реальном времени или пакетного анализа.

Impala дополняет инструменты, доступные для выполнения запросов к большим данным. Она не заменяет фреймворки пакетной обработки на основе MapReduce, такие как Hive. Hive и другие фреймворки на основе MapReduce лучше всего подходят для долгих пакетных задач, таких как те, которые включают пакетную обработку заданий типа Extract, Transform, and Load (ETL).

Impala предоставляет возможность выполнять SQL-запросы значительно быстрее и с минимальной задержкой по сравнению с традиционными методами пакетной обработки данных (например, Hive на основе MapReduce).

Impala предназначена для интерактивного анализа данных, позволяя выполнять запросы в реальном времени и получать результаты почти мгновенно, в то время как Hive и другие инструменты лучше подходят для задач, требующих длительной пакетной обработки.

### **Преимущества Impala**  
Impala предоставляет следующие возможности:

- **Знакомый интерфейс SQL**, который уже известен дата-сайентистам и аналитикам.
- **Возможность выполнения запросов к большим объемам данных** ("big data") в Apache Hadoop.
- **Распределенные запросы в кластерной среде**, что позволяет легко масштабироваться и использовать экономичное оборудование.
- **Совместное использование файлов данных между разными компонентами без необходимости копирования или выполнения операций экспорта/импорта**; например, можно записать данные с помощью Pig, преобразовать их с помощью Hive и выполнять запросы с помощью Impala. Impala может читать и записывать таблицы Hive, что упрощает обмен данными при использовании Impala для аналитики данных, полученных в Hive.
- **Единая система для обработки и анализа больших данных**, которая позволяет избегать затратного моделирования и ETL-процессов исключительно для аналитики.

Таким образом, Impala объединяет мощь SQL с возможностями работы с большими данными и гибким масштабированием в Hadoop, предоставляя удобный и эффективный инструмент для аналитиков и инженеров.

Как Impala работает с Apache Hadoop  
Решение Impala состоит из следующих компонентов:

1. **Клиенты**: Это могут быть Hue, ODBC-клиенты, JDBC-клиенты и оболочка Impala (Impala Shell). Эти интерфейсы обычно используются для выполнения запросов или административных задач, таких как подключение к Impala.

2. **Hive Metastore**: Хранит информацию о данных, доступных для Impala. Например, метахранилище предоставляет Impala информацию о доступных базах данных и их структуре. Когда вы создаете, удаляете или изменяете объекты схемы, загружаете данные в таблицы и выполняете другие действия через SQL-запросы Impala, соответствующие изменения метаданных автоматически передаются всем узлам Impala с помощью специального каталожного сервиса, введенного в Impala 1.2.

3. **Impala**: Этот процесс запускается на DataNodes и координирует и выполняет запросы. Каждая инстанция Impala может принимать, планировать и координировать запросы от клиентов Impala. Запросы распределяются между узлами Impala, и эти узлы действуют как рабочие, выполняя фрагменты запросов параллельно.

4. **HBase и HDFS**: Используются в качестве хранилища данных, к которым выполняются запросы.

Процесс выполнения запросов с помощью Impala выглядит следующим образом:

1. Приложения отправляют SQL-запросы в Impala через ODBC или JDBC, которые предоставляют стандартные интерфейсы для выполнения запросов. Приложение может подключаться к любому `impalad` в кластере, и этот `impalad` становится координатором для данного запроса.
2. Impala анализирует запрос и определяет, какие задачи должны быть выполнены экземплярами `impalad` по всему кластеру. План выполнения составляется с учетом оптимальной эффективности.
3. Локальные экземпляры `impalad` обращаются к службам HDFS и HBase для получения данных.
4. Каждый `impalad` возвращает данные координатору, который затем отправляет результаты обратно клиенту.

Таким образом, Impala обеспечивает распределенную обработку запросов в кластере Hadoop, эффективно распараллеливая задачи для ускорения работы с большими объемами данных.